{"title":"Klasifikasi Persetujuan Permohonan Aplikasi Kartu Kredit","markdown":{"yaml":{"aliases":["/2022/10/25/Credit-Card-Approvals"],"date":"2022-10-25","description":"Artikel ini membahas tentang kasus klasifikasi persetujuan permohonan aplikasi kartu kredit dan membangun model machine learning yang sesuai dengan kasus tersebut.","output-file":"2022-10-25-credit-card-approvals.html","title":"Klasifikasi Persetujuan Permohonan Aplikasi Kartu Kredit","image":"images/Approvals.png","author":"I Made Nusa Yudiskara","categories":["jupyter","code","analysis","classification","logistic regression","data cleaning"]},"headingText":"1. Permohonan aplikasi kartu kredit","containsRefs":false,"markdown":"\n\n\n\nBank komersial mendapatkan banyak form aplikasi untuk membuat kartu kredit. Permintaan kartu kredit ditolak dengan berbagai alasan, contohnya, jumlah hutang yang tinggi, pendapatan rendah, atau masalah lain pada laporan kredit. Memeriksa semua form aplikasi secara manual menghabiskan banyak waktu, dan manusia cenderung membuat kesalahan. Pada artikel ini saya akan mencoba membuat model machine learning untuk memprediksi kelayakan aplikasi kartu kedit secara otomatis\n\n<p>Berikut merupakan dataset <a href=\"http://archive.ics.uci.edu/ml/datasets/credit+approval\">\"Credit Card Approval\"</a> dari UCI Machine Learning Repository.\n\n## 2. Aplikasi kartu kredit\nSemua fitur pada dataset ini tidak diperlihatkan untuk menjaga privasi, namun <a href=\"http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html\">blog ini</a> memberikan penjelasan yang cukup baik mengenai fitur-fitur yang mungkin dapat digunakan. Fitur-fitur yang biasa dadapati pada aplikasi kartu kredit adalah <code>Gender</code>, <code>Age</code>, <code>Debt</code>, <code>Married</code>, <code>BankCustomer</code>, <code>EducationLevel</code>, <code>Ethnicity</code>, <code>YearsEmployed</code>, <code>PriorDefault</code>, <code>Employed</code>, <code>CreditScore</code>, <code>DriversLicense</code>, <code>Citizen</code>, <code>ZipCode</code>, <code>Income</code> dan <code>ApprovalStatus</code>. Saat ini dataset ini hanya kumpulan fitur numerik dan non-numerikal, Masalah ini dapat diperbaiki dengan preprocessing, namun sebelum melakukan preprocessing, sebaiknya kita harus memeriksa semua masalah yang mungkin ada pada dataset ini yang perlu diperbaiki.\n\n## 3. Membagi data menjadi train dan test set\nSekarang, saya akan membagi data menjadi 2 set yaitu train set dan test set. Untuk mempersiapkan data untuk dua tahapan lain dari proses machine learning yaitu training dan testing. Sebaiknya, tidak ada informasi pada test set yang digunakan untuk membantu proses preprocessing pada train set. maka dari itu pertama saya akan membagi data terlebih dahulu kemudian membaginya. Selain itu fitur-fitur seperti <code>DriversLicense</code> dan <code>ZipCode</code> tidak terlalu penting untuk digunakan pada proses training dibandingkan dengan fitur-fitur yang lain untuk memprediksi kelayakan aplikasi kartu kredit\n\n## 4. Mengatasi missing values (part i)\nSetelah data dibagi menjadi train dan test set. kita bisa mulai mengatasi masalah yang kita temui ketika memeriksa dataframe:\n<ul>\n<li>Dataset yang digunakan saat ini memiliki data numerik dan non-numerik(<code>float64</code>, <code>int64</code> dan <code>object</code>)</li>\n<li>Dataset ini juga memiliki berbagai rentang nilai. Ada fitur memiliki rentang nilai 0-28, ada juga yang memiliki rentang 2-67, bahkan 1017-100000.</li>\n<li>Yang terakhir pada dataset beberapa baris pada setiap kolom tidak memiliki nilai (missing values). Missing values pada dataset ditandai dengan simbol ?</li>\n</ul>\n\n## 5. Mengatasi missing values (part ii)\nSemua ? sudah diganti dengan NaN. Ini bertujuan untuk membantu kita untuk pada tahapan selanjutnya untuk mengatasi missing value, yaitu dengan strategi mean imputation \n\n## 6. Mengatasi missing values (part iii)\nKita telah berhasi mengatasi missing values yang ada pada kolom yang memiliki nilai numerikas. namun masih banyak missing values yang perlu di imputasi pada kolom 0, 1, 3, 4, 5, 6, dan 13. Semua kolom ini memiliki nilai non-numerik, maka dari itu strategi mean imputation tidak akan berhasil jika digunakan pada kolom tersebut. Imputasi pada kolom-kolom ini akan dilakukan dengan menggunakan nilai yang sering muncul pada kolom tersebut. Metode ini secara umum baik digunakan ketika melakukan imputasi untuk data kategorikal. \n\n## 7. Data preprocessing (part i)\nSemua missing values telah berhasil diatasi. \nMasih ada beberapa langkah data preprocessing yang diperlukan sebelum mulai membangun model machine learning. Saya akan membagi tahapan preprocessing ini menjadi dua tahapan:\n<ol>\n<li>Ubah data non-numerik menjadi numerik.</li>\n<li>Manipulasi data sehingga semua nilai fitur memiliki rentang nilai yang sama</li>\n</ol>\nPertama, saya akan mengubah semua nilai non-numerik menjadi numerik. Hal ini penting dilakukan untuk mendapatkan proses komputasi yang lebih cepat, selain itu banyak model machine learning (terutama yang ada pada library scikit-learn) mengharuskan data dengan format numerik. Hal ini akan dilakukan dengan menggunakan method <code>get_dummies()</code> dari library pandas.\n\n\n## 8. Data preprocessing (part ii)\nProses preprocessing terakhir adalah mengubah rentang nilai data (Rescaling). untuk menjelaskan proses rescaling saya gunakan contoh fitur <code>CreditScore</code>. Credit score seseorang adalah sebuah nilai kelayakan seseorang untuk memiliki kredit berdasarkan <i>credit history</i> mereka. Semakin tinggi credit score seseorang maka secara finansial mereka akan semakin dipercayai untuk memiliki kredit. Jadi, saya akan melakukan rescaling pada fitur <code>CreditScore</code> dan fitur-fitur lain sehingga memiliki rentang nilai dari 0-1 dimana 0 adalah nilai terendah dan 1 adalah nilai tertinggi\n\n## 9. Fitting model logistic regression dengan train set\nPada dasarnya, memprediksi jika aplikasi kartu kredit akan diterima atau tidak termasuk dalam jenis kasus <a href=\"https://en.wikipedia.org/wiki/Statistical_classification\">klasifikasi</a>. Menurut UCI, dataset yang saya gunakan saat ini memiliki lebih banyak aplikasi yang berstatus \"Denied\" daripada yang berstatus \"Approved\". Dari 690 baris ada 383(55.5%) aplikasi dengan status \"Denied\" dan 307(44.5%) dengan status \"Approved\". Model machine learning yang baik seharusnya dapat secara akurat memprediksi status aplikasi sesuai dengan statistik tersebut.\n\nModel machine learning mana yang sebaiknya kita pilih?. Karena semua kolom yang ada pada dataset ini memiliki korelasi yaitu sebagai nilai ukur layak atau tidaknya sebuah apliksi kartu kredit, saya akan memilih menggunakan <i>Logistic Regression</i> karena model tersebut biasanya memberikan hasil yang baik pada kasus serupa. \n\n## 10. Membuat prediksi dan mengevaluasi model machine learning\nSelanjutnya adalah mengukur seberapa baik performa model machine learning yang telah dibuat.\n\nSaya akan mengevaluasi model ini dengan test set untuk mengukur <a href=\"https://developers.google.com/machine-learning/crash-course/classification/accuracy\">classification accuracy</a>. Tapi sebelum itu saya juga akan melihat <a href=\"http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\">confusion matrix</a> dari model yang telah dibuat. Pada kasus memprediksi kelayakan aplikasi kartu kredit, penting untuk melihat apakah model yang telah dibuat telah berhasil memprediksi status \"Approved\" dan \"Denied\" yang setara dengan frekuensi label pada dataset awal. Jika hasilnya tidak sesuai dengan aspek tersebut, maka mungkin saja model yang dibuat nantinya akan memberikan status \"Approved\" kepada aplikasi yang seharusnya diberikan status denied. Confusion Matrix akan membantu kita untuk memperlihatkan kesesuaian aspek tersebutk.\n\n## 11. Grid searching dan meningkatkan performa model machine learning\nHasil prediksi model cukup baik, bahkan dapat mencapai nilai akurasi 100%.\n\nPada confusion matrix, element pertama dari baris pertama confusion matrix menunjukan \"true negatives\" artinya jumlah aplikasi yang ditolak oleh model dan memang seharusnya ditolak. element terakhir dari baris kedua confusion matrix menunjukan \"true positives\" artinya jumlah aplikasi yang ditolak oleh model dan memang seharusnya ditolak.\n\nModel machine learning yang dihasilkan sangat baik, namun jika model machine learning mendapatkan performa yang tidak sesuai harapan hal yang bisa dilakukan adalah dengan melakukan grid search pada parameter model yang digunakan untuk mencari parameter yang sesuai agar model mendapatkan kemampuan prediksi yang baik. \n\nImplementasi logistic regression terdiri dari beberapa hyperparameter namun saya akan melakukan grid search pada dua hyperparameter berikut\n\n<ul>\n<li>tol</li>\n<li>max_iter</li>\n</ul>\n\n\n## 12. Menentukan model dengan performa yang paling baik\n\nGrid dari nilai hyperparameter telah ditentukan dan telah dibuat dalam bentuk dictionary yang mana akan digunakan <code>GridSearchCV()</code> sebagai salah satu dari parameterny. Sekarang, mulai grid search untuk melihat nilai mana yang memberikan performa terbaik.\n\n<ul>\n<li>Pertama saya akan menginisiasi <code>GridSearchCV()</code> dengan model logistic regression sebelumnya dengan data yang dimiliki. </li>\n<li>Kemudia yang terakhir menyimpan skor terbaik dan nilai parameter yang digunakan</li>\n</ul>\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"output-file":"2022-10-25-credit-card-approvals.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.251","theme":"cosmo","title-block-banner":true,"aliases":["/2022/10/25/Credit-Card-Approvals"],"date":"2022-10-25","description":"Artikel ini membahas tentang kasus klasifikasi persetujuan permohonan aplikasi kartu kredit dan membangun model machine learning yang sesuai dengan kasus tersebut.","title":"Klasifikasi Persetujuan Permohonan Aplikasi Kartu Kredit","image":"images/Approvals.png","author":"I Made Nusa Yudiskara","categories":["jupyter","code","analysis","classification","logistic regression","data cleaning"]},"extensions":{"book":{"multiFile":true}}}}}